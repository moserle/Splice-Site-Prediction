{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splice site prediction on C. Elegans DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEmZ5Z_z7KXJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, average_precision_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n",
    "\n",
    "from squiggle import transform\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, clone_model, Model\n",
    "\n",
    "import shogun as sg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEUZxbAs5XEJ"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the dna string as a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_float_encoding_dict = { 'A': 0.25, 'C': 0.5,  'G': 0.75, 'T': 1.0 }\n",
    "dna_float_decoding_dict = { '0.25': 'A', '0.5': 'C',  '0.75': 'G', '1.0': 'T' }\n",
    "\n",
    "def encode_dna_string_to_floats(dna_string):\n",
    "    float_encoded_dna = []\n",
    "    \n",
    "    for n in dna_string:\n",
    "        float_encoded_dna.append(dna_float_encoding_dict[n])\n",
    "    \n",
    "    return np.array(float_encoded_dna)\n",
    "\n",
    "def decode_dna_string_from_floats(dna_np):\n",
    "    dna_string = ''\n",
    "    \n",
    "    for n in dna_np:\n",
    "        dna_string = dna_string + dna_float_decoding_dict['{0}'.format(n)]\n",
    "    \n",
    "    return dna_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c21cunLrxdB"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/C_elegans_acc_seq.csv', names=['labels', 'sequences'])\n",
    "\n",
    "labels_df = df['labels']\n",
    "dna_sequences = np.array(df['sequences'])\n",
    "\n",
    "encoded_dna_sequences = np.array([encode_dna_string_to_floats(c) for c in dna_sequences])\n",
    "binary_labels = np.array([0 if x == -1 else 1 for x in np.array(labels_df)])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_dna_sequences, np.array(labels_df), test_size=0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (spline site) contains 9.0% of the data samples.\n",
      "For each sample of class 1 there are 11.0 samples of class -1\n",
      "Each sample consists of 82 features, i.e. nucleotides\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels_df)\n",
    "fraction_of_class1_samples = np.array(labels[labels==1]).shape[0] / labels.shape[0]\n",
    "print(\"Class 1 (spline site) contains {0}% of the data samples.\".format(round(fraction_of_class1_samples, 2) * 100))\n",
    "print(\"For each sample of class 1 there are {0} samples of class -1\".format(1/fraction_of_class1_samples))\n",
    "\n",
    "number_of_features = x_train.shape[1]\n",
    "print(\"Each sample consists of {0} features, i.e. nucleotides\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class -1: 0.55\n",
      "Weight for class 1: 5.71\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / y_train[y_train == -1].shape[0])*x_train.shape[0]/2.0\n",
    "weight_for_1 = (1 / y_train[y_train == 1].shape[0])*x_train.shape[0]/2.0\n",
    "\n",
    "class_weight = {-1: weight_for_0, 1: weight_for_1}\n",
    "class_weight_01 = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class -1: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C. Elegans data set is highly unbalanced. the non-spline sites make more than 90% of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  transform(dena_sequences_df[0], method='gates')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 2, 1)\n",
    "plt.scatter(a[0], a[1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 12), dpi= 80, facecolor='w', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(5.5,5.5))\n",
    "\n",
    "\n",
    "# the scatter plot:\n",
    "axScatter = plt.subplot(111)\n",
    "axScatter.scatter(a[0], a[1])\n",
    "\n",
    "# set axes range\n",
    "plt.xlim(-4, 12)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.plot(a[0], a[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a model wrapper and evaluates its performance on the provided evaluation set, outputs the OP, PC and IoU and saves the results in a txt file if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_wrapper, X, Y_true, verbose=False):\n",
    "    Y_pred = model_wrapper.predict(X)\n",
    "    \n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    auroc = roc_auc_score(Y_true, Y_pred)\n",
    "    auprc = average_precision_score(Y_true, Y_pred)\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    acc_per_class = cm.diagonal() / np.sum(cm, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=================================================================\")\n",
    "        print(\"\\nAccuracy:\", round(acc, 5))\n",
    "        print(\"F1:      \", round(f1, 5))\n",
    "        print(\"AUROC    \", round(auroc, 5))\n",
    "        print(\"AUPRC    \", round(auprc, 5))\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy per class\")\n",
    "        print(acc_per_class)\n",
    "        print(\"\\n=================================================================\\n\")\n",
    "    return (f1, acc, acc_per_class, auroc, auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs K-Fold cross-validation and pretty-prints intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_wrapper, X, Y, folds=10, message=''):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    i = 0.\n",
    "    f1_a = 0\n",
    "    acc_a = 0\n",
    "    acc_per_class_a = 0\n",
    "    auroc_a = 0\n",
    "    auprc_a = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model_wrapper.fit(X_train, Y_train)\n",
    "        f1, acc, acc_per_class, auroc, auprc = evaluate_model(model_wrapper, X_test, Y_test)\n",
    "        f1_a += f1\n",
    "        acc_a += acc\n",
    "        acc_per_class_a += acc_per_class\n",
    "        auroc_a += auroc\n",
    "        auprc_a += auprc\n",
    "        i += 1\n",
    "    print(\"\\n=================================================================\")\n",
    "    if message != '':\n",
    "        print(message)\n",
    "    print(\"\\nAverage Accuracy:\", round(acc_a/i, 5))\n",
    "    print(\"Average F1:      \", round(f1_a/i, 5))\n",
    "    print(\"Average AUPRC:      \", round(auprc_a/i, 5))\n",
    "    print(\"Average AUROC:      \", round(auroc_a/i, 5))\n",
    "    print(\"Average Accuracy per class\")\n",
    "    print(acc_per_class_a / i)\n",
    "    print(\"\\n=================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sklearn_Model_Wrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.model.fit(X, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shogun_Model_Wrapper():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        features_train = sg.StringCharFeatures([decode_dna_string_from_floats(c) for c in X], sg.DNA)\n",
    "        labels_train = sg.BinaryLabels(Y)\n",
    "\n",
    "        C = 1.0\n",
    "        epsilon = 0.001\n",
    "        gauss_kernel = sg.WeightedDegreeStringKernel(features_train, features_train, 15)\n",
    "\n",
    "        svm = sg.LibSVM(C, gauss_kernel, labels_train)\n",
    "        svm.set_epsilon(epsilon)\n",
    "        svm.train()\n",
    "        self.model = svm\n",
    "    \n",
    "    def predict(self, X):\n",
    "        features_test = sg.StringCharFeatures([decode_dna_string_from_floats(c) for c in X], sg.DNA)        \n",
    "        return self.model.apply(features_test).get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, loss='categorical_crossentropy', class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ohe = OneHotEncoder()\n",
    "        one_hot_encoded_y = ohe.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "        model = clone_model(self.model)\n",
    "        model.compile(loss=self.loss, optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, one_hot_encoded_y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "        self.trained_model = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.trained_model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, loss='categorical_crossentropy', class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        Y = ((Y+1)/2.).astype(int)\n",
    "        \n",
    "        model = clone_model(self.model)\n",
    "        model.compile(loss=self.loss, optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, Y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "        self.trained_model = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.trained_model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91705\n",
      "Average F1:       0.67428\n",
      "Average AUPRC:       0.23996\n",
      "Average AUROC:       0.64759\n",
      "Average Accuracy per class\n",
      "[0.9757285 0.3194498]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=2000))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.8267\n",
      "Average F1:       0.66958\n",
      "Average AUPRC:       0.26376\n",
      "Average AUROC:       0.81072\n",
      "Average Accuracy per class\n",
      "[0.83058832 0.79084967]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=5000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82557\n",
      "Average F1:       0.66818\n",
      "Average AUPRC:       0.26587\n",
      "Average AUROC:       0.80767\n",
      "Average Accuracy per class\n",
      "[0.82942603 0.78590461]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91648\n",
      "Average F1:       0.68577\n",
      "Average AUPRC:       0.26437\n",
      "Average AUROC:       0.6623\n",
      "Average Accuracy per class\n",
      "[0.97076253 0.35382852]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(SVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight, kernel='poly'))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.4771\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91705\n",
      "Average F1:       0.52673\n",
      "Average AUPRC:       0.13604\n",
      "Average AUROC:       0.52654\n",
      "Average Accuracy per class\n",
      "[1.         0.05308913]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=80, random_state=0, bootstrap=True))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Random Forest\n",
    "As proposed in Breiman (2001), random forest induces each constituent tree from a bootstrap sample of thetraining data. In learning extremely imbalanced data, there is a significant probability that a bootstrap samplecontains few or even none of the minority class, resulting in a tree with poor performance for predictingthe minority class.   A na ̈ıve way of fixing this problem is to use a stratified bootstrap;  i.e.,  sample with replacement from within each class.  \n",
    "This still does not solve the imbalance problem entirely.  As recentresearch shows (e.g., Ling & Li (1998),Kubat & Matwin (1997),Drummond & Holte (2003)), for the treeclassifier, artificially making class priors equal either by down-sampling the majority class or over-samplingthe minority class is usually more effective with respect to a given performance measurement, and that down-sampling seems to have an edge over over-sampling. However, down-sampling the majority class may resultin loss of information, as a large part of the majority class is not used. Random forest inspired us to ensembletrees induced from balanced down-sampled data.  \n",
    "[Ref: https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max deph\n",
    "Compare different values for the maximal depth of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "for i in range(2, 50, 3):\n",
    "    random_forest_max = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "    cross_validation(random_forest_max, x_train, y_train, message=\"10 fold CV for max depth={0}:\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "max depth=8:\n",
      "\n",
      "Average Accuracy: 0.8767\n",
      "Average F1:       0.74685\n",
      "Average AUPRC:       0.39024\n",
      "Average AUROC:       0.90397\n",
      "Average Accuracy per class\n",
      "[0.87050845 0.93743231]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=9:\n",
      "\n",
      "Average Accuracy: 0.87727\n",
      "Average F1:       0.75221\n",
      "Average AUPRC:       0.40357\n",
      "Average AUROC:       0.91387\n",
      "Average Accuracy per class\n",
      "[0.86930187 0.95843944]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=10:\n",
      "\n",
      "Average Accuracy: 0.87841\n",
      "Average F1:       0.74945\n",
      "Average AUPRC:       0.39638\n",
      "Average AUROC:       0.91037\n",
      "Average Accuracy per class\n",
      "[0.8709925  0.94975146]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_max8 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=8, random_state=0))\n",
    "cross_validation(random_forest_max8, x_train, y_train, message=\"max depth={0}:\".format(8))\n",
    "\n",
    "random_forest_max9 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=9, random_state=0))\n",
    "cross_validation(random_forest_max9, x_train, y_train, message=\"max depth={0}:\".format(9))\n",
    "\n",
    "random_forest_max10 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=10, random_state=0))\n",
    "cross_validation(random_forest_max10, x_train, y_train, message=\"max depth={0}:\".format(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90511\n",
      "Average F1:       0.74228\n",
      "Average AUPRC:       0.34086\n",
      "Average AUROC:       0.77992\n",
      "Average Accuracy per class\n",
      "[0.93004834 0.62979583]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',random_state=17)\n",
    "random_forest_max8 = Sklearn_Model_Wrapper(rusboost)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his algorithm is known as EasyEnsemble. The classifier is an ensemble of AdaBoost learners trained on different balanced boostrap samples. The balancing is achieved by random under-sampling.  \n",
    "\n",
    "[Ref: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.ensemble.EasyEnsembleClassifier.html#imblearn.ensemble.EasyEnsembleClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.87784\n",
      "Average F1:       0.6887\n",
      "Average AUPRC:       0.25993\n",
      "Average AUROC:       0.74344\n",
      "Average Accuracy per class\n",
      "[0.90492951 0.58195202]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_200 = EasyEnsembleClassifier(n_estimators=200, random_state=17)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_200)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90227\n",
      "Average F1:       0.7841\n",
      "Average AUPRC:       0.45369\n",
      "Average AUROC:       0.928\n",
      "Average Accuracy per class\n",
      "[0.89807275 0.95792607]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_400)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89886\n",
      "Average F1:       0.78308\n",
      "Average AUPRC:       0.45397\n",
      "Average AUROC:       0.92754\n",
      "Average Accuracy per class\n",
      "[0.89297029 0.96211538]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.8983\n",
      "Average F1:       0.77946\n",
      "Average AUPRC:       0.44397\n",
      "Average AUROC:       0.92191\n",
      "Average Accuracy per class\n",
      "[0.8926303  0.95119048]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4, replacement=True)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91534\n",
      "Average F1:       0.63978\n",
      "Average AUPRC:       0.21153\n",
      "Average AUROC:       0.60848\n",
      "Average Accuracy per class\n",
      "[0.9800495  0.23690129]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = Sklearn_Model_Wrapper(LogisticRegression(random_state=13, max_iter=200))\n",
    "cross_validation(logistic_regression, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.83466\n",
      "Average F1:       0.67386\n",
      "Average AUPRC:       0.2693\n",
      "Average AUROC:       0.80755\n",
      "Average Accuracy per class\n",
      "[0.84051635 0.77457566]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.73523\n",
      "Average F1:       0.60527\n",
      "Average AUPRC:       0.23005\n",
      "Average AUROC:       0.81711\n",
      "Average Accuracy per class\n",
      "[0.7176549  0.91656863]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:100}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we set the weights havely towards the minority class we can the the calassifier overfitting to that class.  \n",
    "In the next experiment we set the class weights to according to the class distribution of the data set. \n",
    "Next we use the default class weights calculated at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82727\n",
      "Average F1:       0.67019\n",
      "Average AUPRC:       0.26988\n",
      "Average AUROC:       0.8149\n",
      "Average Accuracy per class\n",
      "[0.83044675 0.79935055]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=class_weight)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we experiment with different solvers. We increase the max. interations as some solver apperently do not converge with few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=newton-cg\n",
      "\n",
      "Average Accuracy: 0.8358\n",
      "Average F1:       0.68017\n",
      "Average AUPRC:       0.28182\n",
      "Average AUROC:       0.8211\n",
      "Average Accuracy per class\n",
      "[0.83792151 0.80427861]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=lbfgs\n",
      "\n",
      "Average Accuracy: 0.82727\n",
      "Average F1:       0.66946\n",
      "Average AUPRC:       0.26684\n",
      "Average AUROC:       0.80985\n",
      "Average Accuracy per class\n",
      "[0.83186389 0.78784263]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=liblinear\n",
      "\n",
      "Average Accuracy: 0.82841\n",
      "Average F1:       0.67439\n",
      "Average AUPRC:       0.27495\n",
      "Average AUROC:       0.81861\n",
      "Average Accuracy per class\n",
      "[0.83131151 0.80591265]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=sag\n",
      "\n",
      "Average Accuracy: 0.85625\n",
      "Average F1:       0.68726\n",
      "Average AUPRC:       0.27249\n",
      "Average AUROC:       0.7832\n",
      "Average Accuracy per class\n",
      "[0.87181943 0.6945845 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga\n",
      "\n",
      "Average Accuracy: 0.83295\n",
      "Average F1:       0.67849\n",
      "Average AUPRC:       0.28116\n",
      "Average AUROC:       0.82773\n",
      "Average Accuracy per class\n",
      "[0.83515352 0.82029674]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for solver in solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver)\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0}'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use L1 instead of L2 loss. Intuitively L1 seems a better fit than L2 as the features are discrete values.  \n",
    "Indeed we can observe a slight increase of the F1 score and in the accuracies of both classes for the liblinear solver using L1 loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=liblinear and loss=L1\n",
      "\n",
      "Average Accuracy: 0.83409\n",
      "Average F1:       0.67566\n",
      "Average AUPRC:       0.27834\n",
      "Average AUROC:       0.8215\n",
      "Average Accuracy per class\n",
      "[0.83697987 0.80601759]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga and loss=L1\n",
      "\n",
      "Average Accuracy: 0.84205\n",
      "Average F1:       0.68216\n",
      "Average AUPRC:       0.28241\n",
      "Average AUROC:       0.82004\n",
      "Average Accuracy per class\n",
      "[0.84689972 0.79318655]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "l1_solvers = ['liblinear', 'saga']\n",
    "\n",
    "for solver in l1_solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver, penalty='l1')\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0} and loss=L1'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "In this section we experiment with deep learning models.  \n",
    "Because the data only has 82 descret features we focus on simple fully connected networks.  \n",
    "Furthermore we are using five folds instead of ten for our cross-validation to remove bias from our model evaluation.  \n",
    "As deep learning typically requires many samples to properly train on and the Elegants data set is rather small we need to be extra careful to prevent overfitting. As you can see in the section below, even model with only two fully connected layers have far more trainable parameters than we have data features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is a simple fully connected model with three layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(40, activation='relu'))\n",
    "    fully_connected_model.add(Dense(12, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  3320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  492       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  26        \n",
      "=================================================================\n",
      "Total params: 3,838\n",
      "Trainable params: 3,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.4771\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model())\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.77898\n",
      "Average F1:       0.63202\n",
      "Average AUPRC:       0.23724\n",
      "Average AUROC:       0.75885\n",
      "Average Accuracy per class\n",
      "[0.78408257 0.7336131 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper1 = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01)\n",
    "cross_validation(fully_connected_model_wrapper1, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.80398\n",
      "Average F1:       0.64293\n",
      "Average AUPRC:       0.23119\n",
      "Average AUROC:       0.77581\n",
      "Average Accuracy per class\n",
      "[0.81043768 0.74118752]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=10)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.85398\n",
      "Average F1:       0.66682\n",
      "Average AUPRC:       0.2305\n",
      "Average AUROC:       0.73237\n",
      "Average Accuracy per class\n",
      "[0.87880721 0.58592551]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.85852\n",
      "Average F1:       0.6822\n",
      "Average AUPRC:       0.25715\n",
      "Average AUROC:       0.76397\n",
      "Average Accuracy per class\n",
      "[0.87871067 0.64922856]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89659\n",
      "Average F1:       0.70099\n",
      "Average AUPRC:       0.26055\n",
      "Average AUROC:       0.72046\n",
      "Average Accuracy per class\n",
      "[0.93409719 0.50683244]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.88295\n",
      "Average F1:       0.63877\n",
      "Average AUPRC:       0.17898\n",
      "Average AUROC:       0.64576\n",
      "Average Accuracy per class\n",
      "[0.93259045 0.35891981]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model2():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(100, activation='relu'))\n",
    "    fully_connected_model.add(Dense(50, activation='relu'))\n",
    "    fully_connected_model.add(Dense(20, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    fully_connected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             multiple                  8300      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  5050      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  1020      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  42        \n",
      "=================================================================\n",
      "Total params: 14,412\n",
      "Trainable params: 14,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model2()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89716\n",
      "Average F1:       0.66038\n",
      "Average AUPRC:       0.21925\n",
      "Average AUROC:       0.65464\n",
      "Average Accuracy per class\n",
      "[0.94880501 0.36048383]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90568\n",
      "Average F1:       0.67786\n",
      "Average AUPRC:       0.23007\n",
      "Average AUROC:       0.66728\n",
      "Average Accuracy per class\n",
      "[0.95709926 0.37745357]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.70249\n",
      "Average AUPRC:       0.2676\n",
      "Average AUROC:       0.68495\n",
      "Average Accuracy per class\n",
      "[0.96064662 0.40924827]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model3():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(2, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             multiple                  166       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  6         \n",
      "=================================================================\n",
      "Total params: 172\n",
      "Trainable params: 172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model3()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90739\n",
      "Average F1:       0.67741\n",
      "Average AUPRC:       0.24324\n",
      "Average AUROC:       0.66848\n",
      "Average Accuracy per class\n",
      "[0.95974984 0.37720846]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_attention():\n",
    "    X = Input(shape=(82,1))\n",
    "    rnn = Bidirectional(LSTM(128, return_sequences=True, input_shape=(82, 1)))(X)\n",
    "\n",
    "    attentions = []\n",
    "    for _ in range(4):\n",
    "        Q = Dense(8, use_bias=False)(rnn)\n",
    "        V = Dense(8, use_bias=False)(rnn)\n",
    "        K = Dense(8, use_bias=False)(rnn)\n",
    "        attentions.append(Attention()([Q, V, K]))\n",
    "    c = Concatenate()(attentions)\n",
    "    b = BatchNormalization()(c)\n",
    "    f = Flatten()(b)\n",
    "    d = Dropout(.2)(f)\n",
    "    d = Dense(128, activation='relu')(d)\n",
    "    d = Dense(16, activation='relu')(d)\n",
    "    #y = Dense(1, activation='sigmoid', bias_initializer=None)(d)\n",
    "    y = Dense(2, activation='softmax', bias_initializer=None)(d)\n",
    "\n",
    "    m = Model(X, y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 82, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 82, 256)      133120      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 82, 8)        0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 82, 8)        0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 82, 8)        0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 82, 8)        0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 82, 32)       0           attention[0][0]                  \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 82, 32)       128         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2624)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2624)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          336000      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           2064        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            34          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 495,922\n",
      "Trainable params: 495,858\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_attention()\n",
    "lstm.build(input_shape=x_train.shape)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.42273\n",
      "Average F1:       0.24193\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[0.4 0.6]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_wrapper = LSTM_Model_Wrapper(lstm_attention(), loss='binary_crossentropy')\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.42955\n",
      "Average F1:       0.25691\n",
      "Average AUPRC:       0.08686\n",
      "Average AUROC:       0.47635\n",
      "Average Accuracy per class\n",
      "[0.40984478 0.54285714]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_wrapper = LSTM_Model_Wrapper(lstm_attention(), loss='binary_crossentropy', class_weights=class_weight_01)\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shogun Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_string, x_test_string, y_train_string, y_test_string\n",
    "features_train = sg.StringCharFeatures(x_train_string, sg.DNA)\n",
    "features_test = sg.StringCharFeatures(x_test_string, sg.DNA)\n",
    "\n",
    "labels_train = sg.BinaryLabels(y_train_string)\n",
    "\n",
    "C = 1.0\n",
    "epsilon = 0.001\n",
    "gauss_kernel = sg.WeightedDegreeStringKernel(features_train, features_train, 15)\n",
    "\n",
    "svm = sg.LibSVM(C, gauss_kernel, labels_train)\n",
    "svm.set_epsilon(epsilon)\n",
    "\n",
    "svm.train()\n",
    "\n",
    "\n",
    "#labels_predict = svm.apply_binary(features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.95625\n",
      "Average F1:       0.82782\n",
      "Average AUPRC:       0.54229\n",
      "Average AUROC:       0.77628\n",
      "Average Accuracy per class\n",
      "[0.99507582 0.5574762 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shogun_model_wrapper = Shogun_Model_Wrapper()\n",
    "cross_validation(shogun_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Medications Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
