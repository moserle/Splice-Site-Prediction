{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splice site prediction on C. Elegans DNA\n",
    "In this notebook we explore different approaches to predict Splice sites on a C. Elegans DNA dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEmZ5Z_z7KXJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, average_precision_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n",
    "\n",
    "from squiggle import transform\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, clone_model, Model\n",
    "\n",
    "import shogun as sg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEUZxbAs5XEJ"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the dna string as a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_float_encoding_dict = { 'A': 0.25, 'C': 0.5,  'G': 0.75, 'T': 1.0 }\n",
    "dna_float_decoding_dict = { '0.25': 'A', '0.5': 'C',  '0.75': 'G', '1.0': 'T' }\n",
    "\n",
    "def encode_dna_string_to_floats(dna_string):\n",
    "    float_encoded_dna = []\n",
    "    \n",
    "    for n in dna_string:\n",
    "        float_encoded_dna.append(dna_float_encoding_dict[n])\n",
    "    \n",
    "    return np.array(float_encoded_dna)\n",
    "\n",
    "def decode_dna_string_from_floats(dna_np):\n",
    "    dna_string = ''\n",
    "    \n",
    "    for n in dna_np:\n",
    "        dna_string = dna_string + dna_float_decoding_dict['{0}'.format(n)]\n",
    "    \n",
    "    return dna_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a training (80%) and a test set. No model is evaluated on the test split until the final evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c21cunLrxdB"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/C_elegans_acc_seq.csv', names=['labels', 'sequences'])\n",
    "\n",
    "labels_df = df['labels']\n",
    "dna_sequences = np.array(df['sequences'])\n",
    "\n",
    "encoded_dna_sequences = np.array([encode_dna_string_to_floats(c) for c in dna_sequences])\n",
    "binary_labels = np.array([0 if x == -1 else 1 for x in np.array(labels_df)])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_dna_sequences, np.array(labels_df), test_size=0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (spline site) contains 9.0% of the data samples.\n",
      "For each sample of class 1 there are 11.0 samples of class -1\n",
      "Each sample consists of 82 features, i.e. nucleotides\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels_df)\n",
    "fraction_of_class1_samples = np.array(labels[labels==1]).shape[0] / labels.shape[0]\n",
    "print(\"Class 1 (spline site) contains {0}% of the data samples.\".format(round(fraction_of_class1_samples, 2) * 100))\n",
    "print(\"For each sample of class 1 there are {0} samples of class -1\".format(1/fraction_of_class1_samples))\n",
    "\n",
    "number_of_features = x_train.shape[1]\n",
    "print(\"Each sample consists of {0} features, i.e. nucleotides\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C. Elegans data set is highly unbalanced. the non-spline sites make more than 90% of the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights\n",
    "One major approach for data imbalance is to use class weights. We are using a common formula to calculate good weights that we then used in all models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class -1: 0.55\n",
      "Weight for class 1: 5.71\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = (1 / y_train[y_train == -1].shape[0])*x_train.shape[0]/2.0\n",
    "weight_for_1 = (1 / y_train[y_train == 1].shape[0])*x_train.shape[0]/2.0\n",
    "\n",
    "class_weight = {-1: weight_for_0, 1: weight_for_1}\n",
    "class_weight_01 = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class -1: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_file = 'elegans_results_test.csv'\n",
    "with open(test_result_file, 'w', newline='\\n') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    writer.writerow([\"model_name\", \"AUROC\", \"AUPRC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a model wrapper and evaluates its performance on the provided evaluation set, outputs the OP, PC and IoU and saves the results in a csv file if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_wrapper, X, Y_true, verbose=False, model_name=None):\n",
    "    Y_pred = model_wrapper.predict(X)\n",
    "    \n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    auroc = roc_auc_score(Y_true, Y_pred)\n",
    "    auprc = average_precision_score(Y_true, Y_pred)\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    acc_per_class = cm.diagonal() / np.sum(cm, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=================================================================\")\n",
    "        print(\"\\nAccuracy:\", round(acc, 5))\n",
    "        print(\"F1:      \", round(f1, 5))\n",
    "        print(\"AUROC    \", round(auroc, 5))\n",
    "        print(\"AUPRC    \", round(auprc, 5))\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy per class\")\n",
    "        print(acc_per_class)\n",
    "        print(\"\\n=================================================================\\n\")\n",
    "        \n",
    "    if not model_name == None:\n",
    "        with open(test_result_file, 'a', newline='\\n') as f:\n",
    "            writer = csv.writer(f, delimiter=';')\n",
    "            writer.writerow([model_name, round(auprc, 5), round(auprc, 5)])\n",
    "            \n",
    "    return (f1, acc, acc_per_class, auroc, auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs K-Fold cross-validation and pretty-prints intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_wrapper, X, Y, folds=10, message=''):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    i = 0.\n",
    "    f1_a = 0\n",
    "    acc_a = 0\n",
    "    acc_per_class_a = 0\n",
    "    auroc_a = 0\n",
    "    auprc_a = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model_wrapper.fit(X_train, Y_train)\n",
    "        f1, acc, acc_per_class, auroc, auprc = evaluate_model(model_wrapper, X_test, Y_test)\n",
    "        f1_a += f1\n",
    "        acc_a += acc\n",
    "        acc_per_class_a += acc_per_class\n",
    "        auroc_a += auroc\n",
    "        auprc_a += auprc\n",
    "        i += 1\n",
    "    print(\"\\n=================================================================\")\n",
    "    if message != '':\n",
    "        print(message)\n",
    "    print(\"\\nAverage Accuracy:\", round(acc_a/i, 5))\n",
    "    print(\"Average F1:      \", round(f1_a/i, 5))\n",
    "    print(\"Average AUPRC:      \", round(auprc_a/i, 5))\n",
    "    print(\"Average AUROC:      \", round(auroc_a/i, 5))\n",
    "    print(\"Average Accuracy per class\")\n",
    "    print(acc_per_class_a / i)\n",
    "    print(\"\\n=================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(model_wrapper, X, Y):\n",
    "    p, r, t = precision_recall_curve(Y, model_wrapper.predict(X))\n",
    "    apc = average_precision_score(Y, model_wrapper.predict(X))\n",
    "    disp = plt.plot(r, p)\n",
    "    plt.title('2-class Precision-Recall curve: '\n",
    "                    'AP={0:0.2f}'.format(apc))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model_wrapper, X, Y):\n",
    "    fpr, tpr, t = roc_curve(Y, model_wrapper.predict(X))\n",
    "    ras = roc_auc_score(Y, model_wrapper.predict(X))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title('2-class Receiver operating characteristic curve: '\n",
    "                    'ROC_AUC score={0:0.2f}'.format(ras))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sklearn_Model_Wrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.model.fit(X, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shogun_Model_Wrapper():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        features_train = sg.StringCharFeatures([decode_dna_string_from_floats(c) for c in X], sg.DNA)\n",
    "        labels_train = sg.BinaryLabels(Y)\n",
    "\n",
    "        C = 1.0\n",
    "        epsilon = 0.001\n",
    "        gauss_kernel = sg.WeightedDegreeStringKernel(features_train, features_train, 15)\n",
    "\n",
    "        svm = sg.LibSVM(C, gauss_kernel, labels_train)\n",
    "        svm.set_epsilon(epsilon)\n",
    "        svm.train()\n",
    "        self.model = svm\n",
    "    \n",
    "    def predict(self, X):\n",
    "        features_test = sg.StringCharFeatures([decode_dna_string_from_floats(c) for c in X], sg.DNA)        \n",
    "        return self.model.apply(features_test).get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, loss='categorical_crossentropy', class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ohe = OneHotEncoder()\n",
    "        one_hot_encoded_y = ohe.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "        model = clone_model(self.model)\n",
    "        model.compile(loss=self.loss, optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, one_hot_encoded_y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "        self.trained_model = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.trained_model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, loss='categorical_crossentropy', class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        Y = ((Y+1)/2.).astype(int)\n",
    "        \n",
    "        model = clone_model(self.model)\n",
    "        model.compile(loss=self.loss, optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, Y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "        self.trained_model = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.trained_model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this section we experiment with different models and parameters. All models are evaluated using cross validation on the training set. We used the averaged scores over all folds to get a good approximation of how the model performs on new/unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91705\n",
      "Average F1:       0.67428\n",
      "Average AUPRC:       0.23996\n",
      "Average AUROC:       0.64759\n",
      "Average Accuracy per class\n",
      "[0.9757285 0.3194498]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=2000))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.8267\n",
      "Average F1:       0.66958\n",
      "Average AUPRC:       0.26376\n",
      "Average AUROC:       0.81072\n",
      "Average Accuracy per class\n",
      "[0.83058832 0.79084967]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=5000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82557\n",
      "Average F1:       0.66818\n",
      "Average AUPRC:       0.26587\n",
      "Average AUROC:       0.80767\n",
      "Average Accuracy per class\n",
      "[0.82942603 0.78590461]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91648\n",
      "Average F1:       0.68577\n",
      "Average AUPRC:       0.26437\n",
      "Average AUROC:       0.6623\n",
      "Average Accuracy per class\n",
      "[0.97076253 0.35382852]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(SVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight, kernel='poly'))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.4771\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91705\n",
      "Average F1:       0.52673\n",
      "Average AUPRC:       0.13604\n",
      "Average AUROC:       0.52654\n",
      "Average Accuracy per class\n",
      "[1.         0.05308913]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=80, random_state=0, bootstrap=True))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Random Forest\n",
    "As proposed in Breiman (2001), random forest induces each constituent tree from a bootstrap sample of thetraining data. In learning extremely imbalanced data, there is a significant probability that a bootstrap samplecontains few or even none of the minority class, resulting in a tree with poor performance for predictingthe minority class.   A naive way of fixing this problem is to use a stratified bootstrap;  i.e.,  sample with replacement from within each class.  \n",
    "This still does not solve the imbalance problem entirely.  As recentresearch shows artificially making class priors equal either by down-sampling the majority class or over-samplingthe minority class is usually more effective with respect to a given performance measurement, and that down-sampling seems to have an edge over over-sampling. However, down-sampling the majority class may resultin loss of information, as a large part of the majority class is not used. Random forest inspired us to ensembletrees induced from balanced down-sampled data. [Ref](https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf)\n",
    "\n",
    "In this subsection we are using the [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/) library that offers models spesificalls for unbalanced datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max deph\n",
    "Compare different values for the maximal depth of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=2:\n",
      "\n",
      "Average Accuracy: 0.8625\n",
      "Average F1:       0.73401\n",
      "Average AUPRC:       0.38106\n",
      "Average AUROC:       0.90912\n",
      "Average Accuracy per class\n",
      "[0.85260805 0.96564103]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=5:\n",
      "\n",
      "Average Accuracy: 0.87841\n",
      "Average F1:       0.75347\n",
      "Average AUPRC:       0.40212\n",
      "Average AUROC:       0.91259\n",
      "Average Accuracy per class\n",
      "[0.871027   0.95415381]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=8:\n",
      "\n",
      "Average Accuracy: 0.8767\n",
      "Average F1:       0.75287\n",
      "Average AUPRC:       0.40581\n",
      "Average AUROC:       0.91196\n",
      "Average Accuracy per class\n",
      "[0.8693853  0.95453602]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=11:\n",
      "\n",
      "Average Accuracy: 0.8733\n",
      "Average F1:       0.74345\n",
      "Average AUPRC:       0.38542\n",
      "Average AUROC:       0.9078\n",
      "Average Accuracy per class\n",
      "[0.86597446 0.94961652]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=14:\n",
      "\n",
      "Average Accuracy: 0.87898\n",
      "Average F1:       0.75443\n",
      "Average AUPRC:       0.41113\n",
      "Average AUROC:       0.91975\n",
      "Average Accuracy per class\n",
      "[0.87065556 0.96884158]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=17:\n",
      "\n",
      "Average Accuracy: 0.8733\n",
      "Average F1:       0.73868\n",
      "Average AUPRC:       0.37702\n",
      "Average AUROC:       0.89836\n",
      "Average Accuracy per class\n",
      "[0.86822613 0.92850263]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=20:\n",
      "\n",
      "Average Accuracy: 0.87159\n",
      "Average F1:       0.74427\n",
      "Average AUPRC:       0.39185\n",
      "Average AUROC:       0.91271\n",
      "Average Accuracy per class\n",
      "[0.86326211 0.96215092]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=23:\n",
      "\n",
      "Average Accuracy: 0.87443\n",
      "Average F1:       0.74598\n",
      "Average AUPRC:       0.38899\n",
      "Average AUROC:       0.90825\n",
      "Average Accuracy per class\n",
      "[0.86654053 0.94995098]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=26:\n",
      "\n",
      "Average Accuracy: 0.87841\n",
      "Average F1:       0.74896\n",
      "Average AUPRC:       0.39801\n",
      "Average AUROC:       0.91378\n",
      "Average Accuracy per class\n",
      "[0.87135131 0.95621721]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=29:\n",
      "\n",
      "Average Accuracy: 0.8767\n",
      "Average F1:       0.74671\n",
      "Average AUPRC:       0.38831\n",
      "Average AUROC:       0.90299\n",
      "Average Accuracy per class\n",
      "[0.87184525 0.93413866]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=32:\n",
      "\n",
      "Average Accuracy: 0.87443\n",
      "Average F1:       0.74719\n",
      "Average AUPRC:       0.39868\n",
      "Average AUROC:       0.91593\n",
      "Average Accuracy per class\n",
      "[0.86637618 0.96548676]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=35:\n",
      "\n",
      "Average Accuracy: 0.8733\n",
      "Average F1:       0.74288\n",
      "Average AUPRC:       0.38742\n",
      "Average AUROC:       0.90436\n",
      "Average Accuracy per class\n",
      "[0.86667149 0.94205773]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=38:\n",
      "\n",
      "Average Accuracy: 0.87727\n",
      "Average F1:       0.75212\n",
      "Average AUPRC:       0.40101\n",
      "Average AUROC:       0.91296\n",
      "Average Accuracy per class\n",
      "[0.86901128 0.95690476]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=41:\n",
      "\n",
      "Average Accuracy: 0.87955\n",
      "Average F1:       0.75797\n",
      "Average AUPRC:       0.41385\n",
      "Average AUROC:       0.91405\n",
      "Average Accuracy per class\n",
      "[0.871444   0.95666343]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=44:\n",
      "\n",
      "Average Accuracy: 0.88011\n",
      "Average F1:       0.75812\n",
      "Average AUPRC:       0.41206\n",
      "Average AUROC:       0.91921\n",
      "Average Accuracy per class\n",
      "[0.8714946  0.96692748]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=47:\n",
      "\n",
      "Average Accuracy: 0.8767\n",
      "Average F1:       0.7521\n",
      "Average AUPRC:       0.40144\n",
      "Average AUROC:       0.9131\n",
      "Average Accuracy per class\n",
      "[0.86922112 0.95696963]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 50, 3):\n",
    "    random_forest_max = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "    cross_validation(random_forest_max, x_train, y_train, message=\"10 fold CV for max depth={0}:\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "max depth=8:\n",
      "\n",
      "Average Accuracy: 0.8767\n",
      "Average F1:       0.74685\n",
      "Average AUPRC:       0.39024\n",
      "Average AUROC:       0.90397\n",
      "Average Accuracy per class\n",
      "[0.87050845 0.93743231]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=9:\n",
      "\n",
      "Average Accuracy: 0.87727\n",
      "Average F1:       0.75221\n",
      "Average AUPRC:       0.40357\n",
      "Average AUROC:       0.91387\n",
      "Average Accuracy per class\n",
      "[0.86930187 0.95843944]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=10:\n",
      "\n",
      "Average Accuracy: 0.87841\n",
      "Average F1:       0.74945\n",
      "Average AUPRC:       0.39638\n",
      "Average AUROC:       0.91037\n",
      "Average Accuracy per class\n",
      "[0.8709925  0.94975146]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_max8 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=8, random_state=0))\n",
    "cross_validation(random_forest_max8, x_train, y_train, message=\"max depth={0}:\".format(8))\n",
    "\n",
    "random_forest_max9 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=9, random_state=0))\n",
    "cross_validation(random_forest_max9, x_train, y_train, message=\"max depth={0}:\".format(9))\n",
    "\n",
    "random_forest_max10 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=10, random_state=0))\n",
    "cross_validation(random_forest_max10, x_train, y_train, message=\"max depth={0}:\".format(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling learning\n",
    "Imbalanced-learn also offers mutiple algorithms for ensemble learning.  \n",
    "We tried two different algorithms: RUSBoostClassifier and EasyEnsembleClassifier but mainly focused on the second one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90852\n",
      "Average F1:       0.75711\n",
      "Average AUPRC:       0.37321\n",
      "Average AUROC:       0.80635\n",
      "Average Accuracy per class\n",
      "[0.92946223 0.6832351 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',random_state=17)\n",
    "random_forest_max8 = Sklearn_Model_Wrapper(rusboost)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EasyEnsemble](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.ensemble.EasyEnsembleClassifier.html#imblearn.ensemble.EasyEnsembleClassifier) is an ensemble of AdaBoost learners trained on different balanced boostrap samples. The balancing is achieved by random under-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.87784\n",
      "Average F1:       0.6887\n",
      "Average AUPRC:       0.25993\n",
      "Average AUROC:       0.74344\n",
      "Average Accuracy per class\n",
      "[0.90492951 0.58195202]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_200 = EasyEnsembleClassifier(n_estimators=200, random_state=17)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_200)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90227\n",
      "Average F1:       0.7841\n",
      "Average AUPRC:       0.45369\n",
      "Average AUROC:       0.928\n",
      "Average Accuracy per class\n",
      "[0.89807275 0.95792607]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_400)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89943\n",
      "Average F1:       0.78284\n",
      "Average AUPRC:       0.44853\n",
      "Average AUROC:       0.92597\n",
      "Average Accuracy per class\n",
      "[0.89411335 0.95781863]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.8983\n",
      "Average F1:       0.77946\n",
      "Average AUPRC:       0.44397\n",
      "Average AUROC:       0.92191\n",
      "Average Accuracy per class\n",
      "[0.8926303  0.95119048]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4, replacement=True)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "With logistic regression we tried another classical algorithms for binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91534\n",
      "Average F1:       0.63978\n",
      "Average AUPRC:       0.21153\n",
      "Average AUROC:       0.60848\n",
      "Average Accuracy per class\n",
      "[0.9800495  0.23690129]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = Sklearn_Model_Wrapper(LogisticRegression(random_state=13, max_iter=200))\n",
    "cross_validation(logistic_regression, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.83466\n",
      "Average F1:       0.67386\n",
      "Average AUPRC:       0.2693\n",
      "Average AUROC:       0.80755\n",
      "Average Accuracy per class\n",
      "[0.84051635 0.77457566]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.73523\n",
      "Average F1:       0.60527\n",
      "Average AUPRC:       0.23005\n",
      "Average AUROC:       0.81711\n",
      "Average Accuracy per class\n",
      "[0.7176549  0.91656863]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:100}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we set the weights havely towards the minority class we can the the calassifier overfitting to that class.  \n",
    "In the next experiment we set the class weights to according to the class distribution of the data set. \n",
    "Next we use the default class weights calculated at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82727\n",
      "Average F1:       0.67019\n",
      "Average AUPRC:       0.26988\n",
      "Average AUROC:       0.8149\n",
      "Average Accuracy per class\n",
      "[0.83044675 0.79935055]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=class_weight)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we experiment with different solvers. We increase the max. interations as some solver apperently do not converge with few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=newton-cg\n",
      "\n",
      "Average Accuracy: 0.8358\n",
      "Average F1:       0.68017\n",
      "Average AUPRC:       0.28182\n",
      "Average AUROC:       0.8211\n",
      "Average Accuracy per class\n",
      "[0.83792151 0.80427861]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=lbfgs\n",
      "\n",
      "Average Accuracy: 0.82727\n",
      "Average F1:       0.66946\n",
      "Average AUPRC:       0.26684\n",
      "Average AUROC:       0.80985\n",
      "Average Accuracy per class\n",
      "[0.83186389 0.78784263]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=liblinear\n",
      "\n",
      "Average Accuracy: 0.82841\n",
      "Average F1:       0.67439\n",
      "Average AUPRC:       0.27495\n",
      "Average AUROC:       0.81861\n",
      "Average Accuracy per class\n",
      "[0.83131151 0.80591265]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=sag\n",
      "\n",
      "Average Accuracy: 0.85625\n",
      "Average F1:       0.68726\n",
      "Average AUPRC:       0.27249\n",
      "Average AUROC:       0.7832\n",
      "Average Accuracy per class\n",
      "[0.87181943 0.6945845 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga\n",
      "\n",
      "Average Accuracy: 0.83295\n",
      "Average F1:       0.67849\n",
      "Average AUPRC:       0.28116\n",
      "Average AUROC:       0.82773\n",
      "Average Accuracy per class\n",
      "[0.83515352 0.82029674]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for solver in solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver)\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0}'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use L1 instead of L2 loss. Intuitively L1 seems a better fit than L2 as the features are discrete values.  \n",
    "Indeed we can observe a slight increase of the F1 score and in the accuracies of both classes for the liblinear solver using L1 loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=liblinear and loss=L1\n",
      "\n",
      "Average Accuracy: 0.83409\n",
      "Average F1:       0.67566\n",
      "Average AUPRC:       0.27834\n",
      "Average AUROC:       0.8215\n",
      "Average Accuracy per class\n",
      "[0.83697987 0.80601759]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga and loss=L1\n",
      "\n",
      "Average Accuracy: 0.84205\n",
      "Average F1:       0.68216\n",
      "Average AUPRC:       0.28241\n",
      "Average AUROC:       0.82004\n",
      "Average Accuracy per class\n",
      "[0.84689972 0.79318655]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "l1_solvers = ['liblinear', 'saga']\n",
    "\n",
    "for solver in l1_solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver, penalty='l1')\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0} and loss=L1'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "In this section we experiment with deep learning models.  \n",
    "Because the data only has 82 descret features we focus on simple fully connected networks. Furthermore we are using five folds instead of ten for our cross-validation to remove bias from our model evaluation.  \n",
    "As deep learning typically requires many samples to properly train on and the Elegants data set is rather small we need to be extra careful to prevent overfitting. As you can see in the section below, even model with only two fully connected layers have far more trainable parameters than we have data features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is a simple fully connected model with three dense layers. We applied different parameters such as number of epochs or loss in order to find the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(40, activation='relu'))\n",
    "    fully_connected_model.add(Dense(12, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  3320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  492       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  26        \n",
      "=================================================================\n",
      "Total params: 3,838\n",
      "Trainable params: 3,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.4771\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model())\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.77898\n",
      "Average F1:       0.63202\n",
      "Average AUPRC:       0.23724\n",
      "Average AUROC:       0.75885\n",
      "Average Accuracy per class\n",
      "[0.78408257 0.7336131 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper1 = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01)\n",
    "cross_validation(fully_connected_model_wrapper1, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.80398\n",
      "Average F1:       0.64293\n",
      "Average AUPRC:       0.23119\n",
      "Average AUROC:       0.77581\n",
      "Average Accuracy per class\n",
      "[0.81043768 0.74118752]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=10)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.85398\n",
      "Average F1:       0.66682\n",
      "Average AUPRC:       0.2305\n",
      "Average AUROC:       0.73237\n",
      "Average Accuracy per class\n",
      "[0.87880721 0.58592551]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.85852\n",
      "Average F1:       0.6822\n",
      "Average AUPRC:       0.25715\n",
      "Average AUROC:       0.76397\n",
      "Average Accuracy per class\n",
      "[0.87871067 0.64922856]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89659\n",
      "Average F1:       0.70099\n",
      "Average AUPRC:       0.26055\n",
      "Average AUROC:       0.72046\n",
      "Average Accuracy per class\n",
      "[0.93409719 0.50683244]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.88295\n",
      "Average F1:       0.63877\n",
      "Average AUPRC:       0.17898\n",
      "Average AUROC:       0.64576\n",
      "Average Accuracy per class\n",
      "[0.93259045 0.35891981]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied another slightly bigger model to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model2():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(100, activation='relu'))\n",
    "    fully_connected_model.add(Dense(50, activation='relu'))\n",
    "    fully_connected_model.add(Dense(20, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    fully_connected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             multiple                  8300      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  5050      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  1020      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  42        \n",
      "=================================================================\n",
      "Total params: 14,412\n",
      "Trainable params: 14,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model2()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89716\n",
      "Average F1:       0.66038\n",
      "Average AUPRC:       0.21925\n",
      "Average AUROC:       0.65464\n",
      "Average Accuracy per class\n",
      "[0.94880501 0.36048383]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90568\n",
      "Average F1:       0.67786\n",
      "Average AUPRC:       0.23007\n",
      "Average AUROC:       0.66728\n",
      "Average Accuracy per class\n",
      "[0.95709926 0.37745357]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.70249\n",
      "Average AUPRC:       0.2676\n",
      "Average AUROC:       0.68495\n",
      "Average Accuracy per class\n",
      "[0.96064662 0.40924827]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last fully connected model we tried has only two layers and therefore a small number of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model3():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(2, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             multiple                  166       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             multiple                  6         \n",
      "=================================================================\n",
      "Total params: 172\n",
      "Trainable params: 172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model = get_fully_connected_model3()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90739\n",
      "Average F1:       0.67741\n",
      "Average AUPRC:       0.24324\n",
      "Average AUROC:       0.66848\n",
      "Average Accuracy per class\n",
      "[0.95974984 0.37720846]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM\n",
    "Eventhough we focused on fully connected models we also applied one of the LSTMs used in the Human dataset. This model performed very porly and did not seem to converge. Mostly likely due to the small number of samples.  \n",
    "We therefore decided to not further experiment with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_attention():\n",
    "    X = Input(shape=(82,1))\n",
    "    rnn = Bidirectional(LSTM(128, return_sequences=True, input_shape=(82, 1)))(X)\n",
    "\n",
    "    attentions = []\n",
    "    for _ in range(4):\n",
    "        Q = Dense(8, use_bias=False)(rnn)\n",
    "        V = Dense(8, use_bias=False)(rnn)\n",
    "        K = Dense(8, use_bias=False)(rnn)\n",
    "        attentions.append(Attention()([Q, V, K]))\n",
    "    c = Concatenate()(attentions)\n",
    "    b = BatchNormalization()(c)\n",
    "    f = Flatten()(b)\n",
    "    d = Dropout(.2)(f)\n",
    "    d = Dense(128, activation='relu')(d)\n",
    "    d = Dense(16, activation='relu')(d)\n",
    "    #y = Dense(1, activation='sigmoid', bias_initializer=None)(d)\n",
    "    y = Dense(2, activation='softmax', bias_initializer=None)(d)\n",
    "\n",
    "    m = Model(X, y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 82, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 82, 256)      133120      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 82, 8)        2048        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 82, 8)        0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 82, 8)        0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 82, 8)        0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 82, 8)        0           dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 82, 32)       0           attention[0][0]                  \n",
      "                                                                 attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "                                                                 attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 82, 32)       128         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2624)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2624)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          336000      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 16)           2064        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            34          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 495,922\n",
      "Trainable params: 495,858\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_attention()\n",
    "lstm.build(input_shape=x_train.shape)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.42273\n",
      "Average F1:       0.24193\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[0.4 0.6]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_wrapper = LSTM_Model_Wrapper(lstm_attention(), loss='binary_crossentropy')\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.42955\n",
      "Average F1:       0.25691\n",
      "Average AUPRC:       0.08686\n",
      "Average AUROC:       0.47635\n",
      "Average Accuracy per class\n",
      "[0.40984478 0.54285714]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_wrapper = LSTM_Model_Wrapper(lstm_attention(), loss='binary_crossentropy', class_weights=class_weight_01)\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first project we were introduced to Transfer Learning. We dicided to apply a model tzrained on the Human dataset to the Elegans dataset. The Transfer Learning is implemented in the notebook for the Human dataset and is also documented in the raport.  \n",
    "Because we didn't want to erase the cell output and retraining was taking to long we did not include it in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shogun Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_string, x_test_string, y_train_string, y_test_string\n",
    "features_train = sg.StringCharFeatures(x_train_string, sg.DNA)\n",
    "features_test = sg.StringCharFeatures(x_test_string, sg.DNA)\n",
    "\n",
    "labels_train = sg.BinaryLabels(y_train_string)\n",
    "\n",
    "C = 1.0\n",
    "epsilon = 0.001\n",
    "gauss_kernel = sg.WeightedDegreeStringKernel(features_train, features_train, 15)\n",
    "\n",
    "svm = sg.LibSVM(C, gauss_kernel, labels_train)\n",
    "svm.set_epsilon(epsilon)\n",
    "\n",
    "svm.train()\n",
    "\n",
    "\n",
    "#labels_predict = svm.apply_binary(features_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.95625\n",
      "Average F1:       0.82782\n",
      "Average AUPRC:       0.54229\n",
      "Average AUROC:       0.77628\n",
      "Average Accuracy per class\n",
      "[0.99507582 0.5574762 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shogun_model_wrapper = Shogun_Model_Wrapper()\n",
    "cross_validation(shogun_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the best performing models based on their cross validation scores on the training split.    \n",
    "To decide on the best model we looked at the F1 score, the AUROC and the accuracy per class. The best performing models all use the [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/) library.  \n",
    "Based on the cross validation scores we decided to choose the EasyEnsembleClassifier with 400 estimators as our best model.  Note at this point that this choice only considers models that have been trained only on the constructed trining set of the Elegans dataset. The transfer-learning approch achieved higher over all scores. \n",
    "In this section we plot and evaluate our best BalancedRandomForestClassifier and the best EasyEnsembleClassifier on the test set as they both have similar scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_max9 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=9, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Accuracy: 0.84318\n",
      "F1:       0.73517\n",
      "AUROC     0.90284\n",
      "AUPRC     0.39185\n",
      "Confusion matrix:\n",
      "[[326  68]\n",
      " [  1  45]]\n",
      "Accuracy per class\n",
      "[0.82741117 0.97826087]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7351686598801455,\n",
       " 0.8431818181818181,\n",
       " array([0.82741117, 0.97826087]),\n",
       " 0.9028360185389539,\n",
       " 0.39184563993144217)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_max9.fit(x_train, y_train)\n",
    "evaluate_model(random_forest_max9, x_test, y_test, verbose=True, model_name=\"random_forest-max-depth9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pr_curve(random_forest_max9, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(random_forest_max9, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_wrapper.fit(x_train, y_train)\n",
    "evaluate_model(eec_wrapper, x_test, y_test, verbose=True, model_name=\"easyEnsemble_classifier_400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(eec_wrapper, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(eec_wrapper, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model results\n",
    "We write the scores on the test set of the other models we tried to the elegans_results_test.csv file. Please note that these models were not evaluated on the test set prior to this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=5000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',random_state=17)\n",
    "random_forest_max8 = Sklearn_Model_Wrapper(rusboost)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=10)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for solver in solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver)\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0}'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accurately predicting Splice site in C. Elegans DNA strings we have done experiments with multiple different approaches. Our main challenge was the small size of the dataset in combination with its vast class imbalance.  \n",
    "On all models, class weights turned out to be the most important parameter to overcome this imbalance. Our best results hovever were achieved using the [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/) library using bagging and boosting to reduce the imbalance.  \n",
    "However for a real life application we would decide for the transfer learning approach. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Medications Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
