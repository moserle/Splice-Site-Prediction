{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splice site prediction on C. Elegans DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEmZ5Z_z7KXJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, average_precision_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n",
    "\n",
    "from squiggle import transform\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, clone_model, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEUZxbAs5XEJ"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the dna string as a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_float_encoding_dict = { 'A': 0.25, 'C': 0.5,  'G': 0.75, 'T': 1.0 }\n",
    "\n",
    "def encode_dna_string_to_floats(dna_string):\n",
    "    float_encoded_dna = []\n",
    "    \n",
    "    for n in dna_string:\n",
    "        float_encoded_dna.append(dna_float_encoding_dict[n])\n",
    "    \n",
    "    return np.array(float_encoded_dna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c21cunLrxdB"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/C_elegans_acc_seq.csv', names=['labels', 'sequences'])\n",
    "\n",
    "labels_df = df['labels']\n",
    "dena_sequences_df = df['sequences']\n",
    "\n",
    "encoded_dna_sequences = np.array([encode_dna_string_to_floats(c) for c in np.array(dena_sequences_df)])\n",
    "binary_labels = np.array([0 if x == -1 else 1 for x in np.array(labels_df)])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_dna_sequences, np.array(labels_df), test_size=0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtaset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels_df)\n",
    "fraction_of_class1_samples = np.array(labels[labels==1]).shape[0] / labels.shape[0]\n",
    "print(\"Class 1 (spline site) contains {0}% of the data samples.\".format(round(fraction_of_class1_samples, 2) * 100))\n",
    "print(\"For each sample of class 1 there are {0} samples of class -1\".format(1/fraction_of_class1_samples))\n",
    "\n",
    "number_of_features = x_train.shape[1]\n",
    "print(\"Each sample consists of {0} features, i.e. nucleotides\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / y_train[y_train == -1].shape[0])*x_train.shape[0]/2.0\n",
    "weight_for_1 = (1 / y_train[y_train == 1].shape[0])*x_train.shape[0]/2.0\n",
    "\n",
    "class_weight = {-1: weight_for_0, 1: weight_for_1}\n",
    "class_weight_01 = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class -1: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C. Elegans data set is highly unbalanced. the non-spline sites make more than 90% of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  transform(dena_sequences_df[0], method='gates')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 2, 1)\n",
    "plt.scatter(a[0], a[1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 12), dpi= 80, facecolor='w', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(5.5,5.5))\n",
    "\n",
    "\n",
    "# the scatter plot:\n",
    "axScatter = plt.subplot(111)\n",
    "axScatter.scatter(a[0], a[1])\n",
    "\n",
    "# set axes range\n",
    "plt.xlim(-4, 12)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.plot(a[0], a[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a model wrapper and evaluates its performance on the provided evaluation set, outputs the OP, PC and IoU and saves the results in a txt file if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_wrapper, X, Y_true, verbose=False):\n",
    "    Y_pred = model_wrapper.predict(X)\n",
    "    \n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    auroc = roc_auc_score(Y_true, Y_pred)\n",
    "    auprc = average_precision_score(Y_true, Y_pred)\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    acc_per_class = cm.diagonal() / np.sum(cm, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=================================================================\")\n",
    "        print(\"\\nAccuracy:\", round(acc, 5))\n",
    "        print(\"F1:      \", round(f1, 5))\n",
    "        print(\"AUROC    \", round(auroc, 5))\n",
    "        print(\"AUPRC    \", round(auprc, 5))\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy per class\")\n",
    "        print(acc_per_class)\n",
    "        print(\"\\n=================================================================\\n\")\n",
    "    return (f1, acc, acc_per_class, auroc, auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs K-Fold cross-validation and pretty-prints intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_wrapper, X, Y, folds=10, message=''):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    i = 0.\n",
    "    f1_a = 0\n",
    "    acc_a = 0\n",
    "    acc_per_class_a = 0\n",
    "    auroc_a = 0\n",
    "    auprc_a = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model_wrapper.fit(X_train, Y_train)\n",
    "        f1, acc, acc_per_class, auroc, auprc = evaluate_model(model_wrapper, X_test, Y_test)\n",
    "        f1_a += f1\n",
    "        acc_a += acc\n",
    "        acc_per_class_a += acc_per_class\n",
    "        auroc_a += auroc\n",
    "        auprc_a += auprc\n",
    "        i += 1\n",
    "    print(\"\\n=================================================================\")\n",
    "    if message != '':\n",
    "        print(message)\n",
    "    print(\"\\nAverage Accuracy:\", round(acc_a/i, 5))\n",
    "    print(\"Average F1:      \", round(f1_a/i, 5))\n",
    "    print(\"Average AUPRC:      \", round(auprc_a/i, 5))\n",
    "    print(\"Average AUROC:      \", round(auroc_a/i, 5))\n",
    "    print(\"Average Accuracy per class\")\n",
    "    print(acc_per_class_a / i)\n",
    "    print(\"\\n=================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sklearn_Model_Wrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.model.fit(X, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, loss='categorical_crossentropy', class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.loss = loss\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ohe = OneHotEncoder()\n",
    "        one_hot_encoded_y = ohe.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "        model = clone_model(self.model)\n",
    "        model.compile(loss=self.loss, optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, one_hot_encoded_y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "        self.trained_model = model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.trained_model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=2000))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=5000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Sklearn_Model_Wrapper(SVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=class_weight, kernel='poly'))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=80, random_state=0, bootstrap=True))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Random Forest\n",
    "As proposed in Breiman (2001), random forest induces each constituent tree from a bootstrap sample of thetraining data. In learning extremely imbalanced data, there is a significant probability that a bootstrap samplecontains few or even none of the minority class, resulting in a tree with poor performance for predictingthe minority class.   A na ̈ıve way of fixing this problem is to use a stratified bootstrap;  i.e.,  sample with replacement from within each class.  \n",
    "This still does not solve the imbalance problem entirely.  As recentresearch shows (e.g., Ling & Li (1998),Kubat & Matwin (1997),Drummond & Holte (2003)), for the treeclassifier, artificially making class priors equal either by down-sampling the majority class or over-samplingthe minority class is usually more effective with respect to a given performance measurement, and that down-sampling seems to have an edge over over-sampling. However, down-sampling the majority class may resultin loss of information, as a large part of the majority class is not used. Random forest inspired us to ensembletrees induced from balanced down-sampled data.  \n",
    "[Ref: https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max deph\n",
    "Compare different values for the maximal depth of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "for i in range(2, 50, 3):\n",
    "    random_forest_max = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "    cross_validation(random_forest_max, x_train, y_train, message=\"10 fold CV for max depth={0}:\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_max8 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=8, random_state=0))\n",
    "cross_validation(random_forest_max8, x_train, y_train, message=\"max depth={0}:\".format(8))\n",
    "\n",
    "random_forest_max9 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=9, random_state=0))\n",
    "cross_validation(random_forest_max9, x_train, y_train, message=\"max depth={0}:\".format(9))\n",
    "\n",
    "random_forest_max10 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=10, random_state=0))\n",
    "cross_validation(random_forest_max10, x_train, y_train, message=\"max depth={0}:\".format(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(random_forest_max10, x_test, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',random_state=17)\n",
    "random_forest_max8 = Sklearn_Model_Wrapper(rusboost)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his algorithm is known as EasyEnsemble. The classifier is an ensemble of AdaBoost learners trained on different balanced boostrap samples. The balancing is achieved by random under-sampling.  \n",
    "\n",
    "[Ref: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.ensemble.EasyEnsembleClassifier.html#imblearn.ensemble.EasyEnsembleClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_200 = EasyEnsembleClassifier(n_estimators=200, random_state=17)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_200)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_400)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=600, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4, replacement=True)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = Sklearn_Model_Wrapper(LogisticRegression(random_state=13, max_iter=200))\n",
    "cross_validation(logistic_regression, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {-1:1, 1:100}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we set the weights havely towards the minority class we can the the calassifier overfitting to that class.  \n",
    "In the next experiment we set the class weights to according to the class distribution of the data set. \n",
    "Next we use the default class weights calculated at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=class_weight)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we experiment with different solvers. We increase the max. interations as some solver apperently do not converge with few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for solver in solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver)\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0}'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use L1 instead of L2 loss. Intuitively L1 seems a better fit than L2 as the features are discrete values.  \n",
    "Indeed we can observe a slight increase of the F1 score and in the accuracies of both classes for the liblinear solver using L1 loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_solvers = ['liblinear', 'saga']\n",
    "\n",
    "for solver in l1_solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=class_weight, solver=solver, penalty='l1')\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0} and loss=L1'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "In this section we experiment with deep learning models.  \n",
    "Because the data only has 82 descret features we focus on simple fully connected networks.  \n",
    "Furthermore we are using five folds instead of ten for our cross-validation to remove bias from our model evaluation.  \n",
    "As deep learning typically requires many samples to properly train on and the Elegants data set is rather small we need to be extra careful to prevent overfitting. As you can see in the section below, even model with only two fully connected layers have far more trainable parameters than we have data features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is a simple fully connected model with three layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(40, activation='relu'))\n",
    "    fully_connected_model.add(Dense(12, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model = get_fully_connected_model()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model())\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper1 = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01)\n",
    "cross_validation(fully_connected_model_wrapper1, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=10)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model2():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(100, activation='relu'))\n",
    "    fully_connected_model.add(Dense(50, activation='relu'))\n",
    "    fully_connected_model.add(Dense(20, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    fully_connected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model = get_fully_connected_model2()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), loss='binary_crossentropy', class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model3():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(2, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model = get_fully_connected_model3()\n",
    "fully_connected_model.build(input_shape=x_train.shape)\n",
    "fully_connected_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weight_01, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_attention():\n",
    "    X = Input(shape=(82,1))\n",
    "    rnn = Bidirectional(LSTM(128, return_sequences=True, input_shape=(82, 1)))(X)\n",
    "\n",
    "    attentions = []\n",
    "    for _ in range(4):\n",
    "        Q = Dense(8, use_bias=False)(rnn)\n",
    "        V = Dense(8, use_bias=False)(rnn)\n",
    "        K = Dense(8, use_bias=False)(rnn)\n",
    "        attentions.append(Attention()([Q, V, K]))\n",
    "    c = Concatenate()(attentions)\n",
    "    b = BatchNormalization()(c)\n",
    "    f = Flatten()(b)\n",
    "    d = Dropout(.2)(f)\n",
    "    d = Dense(128, activation='relu')(d)\n",
    "    d = Dense(128, activation='relu')(d)\n",
    "    y = Dense(2, activation='softmax', bias_initializer=None)(d)\n",
    "\n",
    "    m = Model(X, y)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           [(None, 82, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 82, 256)      133120      input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_522 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_523 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_524 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_525 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_526 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_527 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_528 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_529 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_530 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_531 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_532 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_533 (Dense)               (None, 82, 8)        2048        bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_132 (Attention)       (None, 82, 8)        0           dense_522[0][0]                  \n",
      "                                                                 dense_523[0][0]                  \n",
      "                                                                 dense_524[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_133 (Attention)       (None, 82, 8)        0           dense_525[0][0]                  \n",
      "                                                                 dense_526[0][0]                  \n",
      "                                                                 dense_527[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_134 (Attention)       (None, 82, 8)        0           dense_528[0][0]                  \n",
      "                                                                 dense_529[0][0]                  \n",
      "                                                                 dense_530[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_135 (Attention)       (None, 82, 8)        0           dense_531[0][0]                  \n",
      "                                                                 dense_532[0][0]                  \n",
      "                                                                 dense_533[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 82, 32)       0           attention_132[0][0]              \n",
      "                                                                 attention_133[0][0]              \n",
      "                                                                 attention_134[0][0]              \n",
      "                                                                 attention_135[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 82, 32)       128         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 2624)         0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 2624)         0           flatten_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_534 (Dense)               (None, 128)          336000      dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_535 (Dense)               (None, 128)          16512       dense_534[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_536 (Dense)               (None, 2)            258         dense_535[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 510,594\n",
      "Trainable params: 510,530\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_attention()\n",
    "lstm.build(input_shape=x_train.shape)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9125\n",
      "Average F1:       0.47706\n",
      "Average AUPRC:       0.0875\n",
      "Average AUROC:       0.5\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model_wrapper = Keras_Model_Wrapper(lstm_attention(), loss='binary_crossentropy')\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_wrapper = Keras_Model_Wrapper(lstm_attention(), loss='binary_crossentropy', epochs=100, batch_size=100)\n",
    "cross_validation(lstm_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Medications Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
