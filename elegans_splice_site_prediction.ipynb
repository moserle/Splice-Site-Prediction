{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splice site prediction on C. Elegans DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEmZ5Z_z7KXJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, average_precision_score, roc_auc_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier, EasyEnsembleClassifier\n",
    "\n",
    "from squiggle import transform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEUZxbAs5XEJ"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the dna string as a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_float_encoding_dict = { 'A': 0.25, 'C': 0.5,  'G': 0.75, 'T': 1.0 }\n",
    "\n",
    "def encode_dna_string_to_floats(dna_string):\n",
    "    float_encoded_dna = []\n",
    "    \n",
    "    for n in dna_string:\n",
    "        float_encoded_dna.append(dna_float_encoding_dict[n])\n",
    "    \n",
    "    return np.array(float_encoded_dna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c21cunLrxdB"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/C_elegans_acc_seq.csv', names=['labels', 'sequences'])\n",
    "\n",
    "labels_df = df['labels']\n",
    "dena_sequences_df = df['sequences']\n",
    "\n",
    "encoded_dna_sequences = np.array([encode_dna_string_to_floats(c) for c in np.array(dena_sequences_df)])\n",
    "binary_labels = np.array([0 if x == -1 else 1 for x in np.array(labels_df)])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_dna_sequences, np.array(labels_df), test_size=0.25, random_state=29)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(encoded_dna_sequences, binary_labels, test_size=0.25, random_state=29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtaset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (spline site) contains 9.0% of the data samples.\n",
      "For each sample of class 1 there are 11.0 samples of class -1\n",
      "Each sample consists of 82 features, i.e. nucleotides\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels_df)\n",
    "fraction_of_class1_samples = np.array(labels[labels==1]).shape[0] / labels.shape[0]\n",
    "print(\"Class 1 (spline site) contains {0}% of the data samples.\".format(round(fraction_of_class1_samples, 2) * 100))\n",
    "print(\"For each sample of class 1 there are {0} samples of class -1\".format(1/fraction_of_class1_samples))\n",
    "\n",
    "number_of_features = x_train.shape[1]\n",
    "print(\"Each sample consists of {0} features, i.e. nucleotides\".format(number_of_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C. Elegans data set is highly unbalanced. the non-spline sites make more than 90% of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, -1, -1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 5, 6, 6, 7, 7, 6, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 4, 3, 3, 3, 3, 4, 5, 5, 6, 6, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 10, 9, 9], [0, -1, -1, 0, 0, 0, 0, -1, 0, -1, -2, -1, 0, 1, 1, 0, -1, -2, -2, -3, -4, -3, -4, -5, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 3, 2, 1, 2, 3, 3, 4, 3, 3, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 8, 8, 8, 7, 8, 8, 8, 7, 6, 5, 5, 5, 4, 4, 5, 5, 5, 4, 5, 5, 4, 5, 5, 6, 7, 7, 6, 6, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "a =  transform(dena_sequences_df[0], method='gates')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1120x960 with 0 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1120x960 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3, 2, 1)\n",
    "plt.scatter(a[0], a[1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 12), dpi= 80, facecolor='w', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d8f4b1c5f8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 396x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1, figsize=(5.5,5.5))\n",
    "\n",
    "\n",
    "# the scatter plot:\n",
    "axScatter = plt.subplot(111)\n",
    "axScatter.scatter(a[0], a[1])\n",
    "\n",
    "# set axes range\n",
    "plt.xlim(-4, 12)\n",
    "plt.ylim(-10, 10)\n",
    "\n",
    "plt.plot(a[0], a[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes a model wrapper and evaluates its performance on the provided evaluation set, outputs the OP, PC and IoU and saves the results in a txt file if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_wrapper, X, Y_true, verbose=False):\n",
    "    Y_pred = model_wrapper.predict(X)\n",
    "    \n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"macro\")\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    auroc = roc_auc_score(Y_true, Y_pred)\n",
    "    auprc = average_precision_score(Y_true, Y_pred)\n",
    "    cm = confusion_matrix(Y_true, Y_pred)\n",
    "    acc_per_class = cm.diagonal() / np.sum(cm, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=================================================================\")\n",
    "        print(\"\\nAccuracy:\", round(acc, 5))\n",
    "        print(\"F1:      \", round(f1, 5))\n",
    "        print(\"AUROC    \", round(auroc, 5))\n",
    "        print(\"AUPRC    \", round(auprc, 5))\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy per class\")\n",
    "        print(acc_per_class)\n",
    "        print(\"\\n=================================================================\\n\")\n",
    "    return (f1, acc, acc_per_class, auroc, auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs K-Fold cross-validation and pretty-prints intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_wrapper, X, Y, folds=10, message=''):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    i = 0.\n",
    "    f1_a = 0\n",
    "    acc_a = 0\n",
    "    acc_per_class_a = 0\n",
    "    auroc_a = 0\n",
    "    auprc_a = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model_wrapper.fit(X_train, Y_train)\n",
    "        f1, acc, acc_per_class, auroc, auprc = evaluate_model(model_wrapper, X_test, Y_test)\n",
    "        f1_a += f1\n",
    "        acc_a += acc\n",
    "        acc_per_class_a += acc_per_class\n",
    "        auroc_a += auroc\n",
    "        auprc_a += auprc\n",
    "        i += 1\n",
    "    print(\"\\n=================================================================\")\n",
    "    if message != '':\n",
    "        print(message)\n",
    "    print(\"\\nAverage Accuracy:\", round(acc_a/i, 5))\n",
    "    print(\"Average F1:      \", round(f1_a/i, 5))\n",
    "    print(\"Average AUPRC:      \", round(auprc_a/i, 5))\n",
    "    print(\"Average AUROC:      \", round(auroc_a/i, 5))\n",
    "    print(\"Average Accuracy per class\")\n",
    "    print(acc_per_class_a / i)\n",
    "    print(\"\\n=================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sklearn_Model_Wrapper():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.model.fit(X, Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keras_Model_Wrapper():\n",
    "    def __init__(self, model, batch_size=64, epochs=10, class_weights={0:1, 1:1}):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ohe = OneHotEncoder()\n",
    "        one_hot_encoded_y = ohe.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "        self.model.fit(X, one_hot_encoded_y, class_weight=self.class_weights, \n",
    "                       batch_size=self.batch_size, epochs=self.epochs, verbose=0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probas = self.model.predict(X)\n",
    "        predictions = np.argmax(probas, axis=1)\n",
    "        return np.array([-1 if x == 0 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91394\n",
      "Average F1:       0.66453\n",
      "Average AUPRC:       0.21742\n",
      "Average AUROC:       0.63865\n",
      "Average Accuracy per class\n",
      "[0.97210135 0.30519059]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=2000))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.81758\n",
      "Average F1:       0.65798\n",
      "Average Accuracy per class\n",
      "[0.81990876 0.77870215]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:0.1, 1:1}\n",
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=5000, class_weight=weights))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82485\n",
      "Average F1:       0.66426\n",
      "Average Accuracy per class\n",
      "[0.82845915 0.77203548]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "svm = Sklearn_Model_Wrapper(LinearSVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=weights))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.78788\n",
      "Average F1:       0.64461\n",
      "Average Accuracy per class\n",
      "[0.77827839 0.88528945]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "svm = Sklearn_Model_Wrapper(SVC(random_state=0, tol=1e-5, max_iter=10000, class_weight=weights, kernel='poly'))\n",
    "\n",
    "cross_validation(svm, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91333\n",
      "Average F1:       0.47732\n",
      "Average Accuracy per class\n",
      "[1. 0.]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=2, random_state=0))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91879\n",
      "Average F1:       0.54185\n",
      "Average Accuracy per class\n",
      "[0.99870124 0.07446312]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = Sklearn_Model_Wrapper(RandomForestClassifier(max_depth=80, random_state=0, bootstrap=True))\n",
    "\n",
    "cross_validation(random_forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanced Random Forest\n",
    "As proposed in Breiman (2001), random forest induces each constituent tree from a bootstrap sample of thetraining data. In learning extremely imbalanced data, there is a significant probability that a bootstrap samplecontains few or even none of the minority class, resulting in a tree with poor performance for predictingthe minority class.   A na ̈ıve way of fixing this problem is to use a stratified bootstrap;  i.e.,  sample with replacement from within each class.  \n",
    "This still does not solve the imbalance problem entirely.  As recentresearch shows (e.g., Ling & Li (1998),Kubat & Matwin (1997),Drummond & Holte (2003)), for the treeclassifier, artificially making class priors equal either by down-sampling the majority class or over-samplingthe minority class is usually more effective with respect to a given performance measurement, and that down-sampling seems to have an edge over over-sampling. However, down-sampling the majority class may resultin loss of information, as a large part of the majority class is not used. Random forest inspired us to ensembletrees induced from balanced down-sampled data.  \n",
    "[Ref: https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Max deph\n",
    "Compare different values for the maximal depth of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=2:\n",
      "\n",
      "Average Accuracy: 0.85515\n",
      "Average F1:       0.72456\n",
      "Average Accuracy per class\n",
      "[0.84509992 0.94944444]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=5:\n",
      "\n",
      "Average Accuracy: 0.86485\n",
      "Average F1:       0.73472\n",
      "Average Accuracy per class\n",
      "[0.85564973 0.95063492]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=8:\n",
      "\n",
      "Average Accuracy: 0.87091\n",
      "Average F1:       0.74108\n",
      "Average Accuracy per class\n",
      "[0.86373979 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=11:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=14:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=17:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=20:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=23:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=26:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=29:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=32:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=35:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=38:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=41:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=44:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "10 fold CV for max depth=47:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "for i in range(2, 50, 3):\n",
    "    random_forest_max = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "    cross_validation(random_forest_max, x_train, y_train, message=\"10 fold CV for max depth={0}:\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "max depth=8:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=9:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "max depth=10:\n",
      "\n",
      "Average Accuracy: 0.8703\n",
      "Average F1:       0.74034\n",
      "Average Accuracy per class\n",
      "[0.86309022 0.93760971]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_max8 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "cross_validation(random_forest_max8, x_train, y_train, message=\"max depth={0}:\".format(8))\n",
    "\n",
    "random_forest_max9 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "cross_validation(random_forest_max9, x_train, y_train, message=\"max depth={0}:\".format(9))\n",
    "\n",
    "random_forest_max10 = Sklearn_Model_Wrapper(BalancedRandomForestClassifier(max_depth=i, random_state=0))\n",
    "cross_validation(random_forest_max10, x_train, y_train, message=\"max depth={0}:\".format(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89091\n",
      "Average F1:       0.72985\n",
      "Average Accuracy per class\n",
      "[0.91017886 0.6787535 ]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rusboost = RUSBoostClassifier(n_estimators=200, algorithm='SAMME.R',random_state=17)\n",
    "random_forest_max8 = Sklearn_Model_Wrapper(rusboost)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his algorithm is known as EasyEnsemble. The classifier is an ensemble of AdaBoost learners trained on different balanced boostrap samples. The balancing is achieved by random under-sampling.  \n",
    "\n",
    "[Ref: https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.ensemble.EasyEnsembleClassifier.html#imblearn.ensemble.EasyEnsembleClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9\n",
      "Average F1:       0.77992\n",
      "Average Accuracy per class\n",
      "[0.89553779 0.93475257]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_200 = EasyEnsembleClassifier(n_estimators=200, random_state=17)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_200)\n",
    "cross_validation(random_forest_max8, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90061\n",
      "Average F1:       0.78018\n",
      "Average Accuracy per class\n",
      "[0.89626682 0.93475257]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_400 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_400)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89939\n",
      "Average F1:       0.77846\n",
      "Average Accuracy per class\n",
      "[0.89491988 0.93475257]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=600, random_state=17, n_jobs=4)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.89333\n",
      "Average F1:       0.77056\n",
      "Average Accuracy per class\n",
      "[0.8882862  0.93475257]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eec_600 = EasyEnsembleClassifier(n_estimators=400, random_state=17, n_jobs=4, replacement=True)\n",
    "eec_wrapper = Sklearn_Model_Wrapper(eec_600)\n",
    "cross_validation(eec_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.91212\n",
      "Average F1:       0.61782\n",
      "Average Accuracy per class\n",
      "[0.97818713 0.20710084]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = Sklearn_Model_Wrapper(LogisticRegression(random_state=13, max_iter=200))\n",
    "cross_validation(logistic_regression, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.83273\n",
      "Average F1:       0.67162\n",
      "Average Accuracy per class\n",
      "[0.83775179 0.76781979]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:10}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.73152\n",
      "Average F1:       0.59575\n",
      "Average Accuracy per class\n",
      "[0.71584757 0.88220355]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:100}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we set the weights havely towards the minority class we can the the calassifier overfitting to that class.  \n",
    "In the next experiment we set the class weights to according to the class distribution of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.82606\n",
      "Average F1:       0.66536\n",
      "Average Accuracy per class\n",
      "[0.82976304 0.77370215]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:11}\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state=13, max_iter=200, class_weight=weights)\n",
    "logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "cross_validation(logistic_regression_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we experiment with different solvers. We increase the max. interations as some solver apperently do not converge with few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=newton-cg\n",
      "\n",
      "Average Accuracy: 0.82606\n",
      "Average F1:       0.66536\n",
      "Average Accuracy per class\n",
      "[0.82976304 0.77370215]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=lbfgs\n",
      "\n",
      "Average Accuracy: 0.82606\n",
      "Average F1:       0.66536\n",
      "Average Accuracy per class\n",
      "[0.82976304 0.77370215]\n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "=================================================================\n",
      "solver=liblinear\n",
      "\n",
      "Average Accuracy: 0.81758\n",
      "Average F1:       0.65788\n",
      "Average Accuracy per class\n",
      "[0.81992254 0.77870215]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=sag\n",
      "\n",
      "Average Accuracy: 0.84182\n",
      "Average F1:       0.62482\n",
      "Average Accuracy per class\n",
      "[0.86915303 0.54507003]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga\n",
      "\n",
      "Average Accuracy: 0.79152\n",
      "Average F1:       0.61119\n",
      "Average Accuracy per class\n",
      "[0.79227676 0.74387955]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:11}\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "for solver in solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=weights, solver=solver)\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0}'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use L1 instead of L2 loss. Intuitively L1 seems a better fit than L2 as the features are discrete values.  \n",
    "Indeed we can observe a slight increase of the F1 score and in the accuracies of both classes for the liblinear solver using L1 loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=liblinear and loss=L1\n",
      "\n",
      "Average Accuracy: 0.8297\n",
      "Average F1:       0.6711\n",
      "Average Accuracy per class\n",
      "[0.83251486 0.78703548]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "solver=saga and loss=L1\n",
      "\n",
      "Average Accuracy: 0.79758\n",
      "Average F1:       0.64197\n",
      "Average Accuracy per class\n",
      "[0.79606247 0.80069561]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_lev\\Anaconda3\\envs\\ml4hc-p4\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "weights = {-1:1, 1:11}\n",
    "l1_solvers = ['liblinear', 'saga']\n",
    "\n",
    "for solver in l1_solvers:\n",
    "    logistic_regression = LogisticRegression(random_state=13, max_iter=10000, class_weight=weights, solver=solver, penalty='l1')\n",
    "    logistic_regression_wrapper = Sklearn_Model_Wrapper(logistic_regression)\n",
    "    cross_validation(logistic_regression_wrapper, x_train, y_train, message='solver={0} and loss=L1'.format(solver))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(40, activation='relu'))\n",
    "    fully_connected_model.add(Dense(12, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    fully_connected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.94485\n",
      "Average F1:       0.75905\n",
      "Average Accuracy per class\n",
      "[0.98741753 0.48571895]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model())\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.90545\n",
      "Average F1:       0.78838\n",
      "Average Accuracy per class\n",
      "[0.90820815 0.85164169]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper1 = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weights)\n",
    "cross_validation(fully_connected_model_wrapper1, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.94242\n",
      "Average F1:       0.88702\n",
      "Average Accuracy per class\n",
      "[0.93960268 0.97564103]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weights, epochs=20)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.97515\n",
      "Average F1:       0.93131\n",
      "Average AUPRC:       0.8266\n",
      "Average AUROC:       0.94022\n",
      "Average Accuracy per class\n",
      "[0.98338059 0.89705882]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weights, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.9903\n",
      "Average F1:       0.96875\n",
      "Average Accuracy per class\n",
      "[0.99407448 0.94820513]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weights, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.98848\n",
      "Average F1:       0.96079\n",
      "Average Accuracy per class\n",
      "[0.99406571 0.92896825]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model(), class_weights=class_weights, epochs=1000)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_connected_model2():\n",
    "    fully_connected_model = Sequential()\n",
    "    fully_connected_model.add(Dense(20, activation='relu'))\n",
    "    fully_connected_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    fully_connected_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return fully_connected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.93394\n",
      "Average F1:       0.85532\n",
      "Average Accuracy per class\n",
      "[0.93667388 0.90541635]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weights, epochs=50)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "\n",
      "Average Accuracy: 0.97212\n",
      "Average F1:       0.93489\n",
      "Average Accuracy per class\n",
      "[0.97511459 0.94589358]\n",
      "\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0:1, 1:10}\n",
    "fully_connected_model_wrapper = Keras_Model_Wrapper(get_fully_connected_model2(), class_weights=class_weights, epochs=100)\n",
    "cross_validation(fully_connected_model_wrapper, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Medications Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
